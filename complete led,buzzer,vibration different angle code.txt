import os
import cv2
import numpy as np
import dlib
from imutils import face_utils
import RPi.GPIO as GPIO
import time
import json
import paho.mqtt.client as mqtt

# Set Qt platform to avoid errors when running OpenCV on Raspberry Pi
os.environ["QT_QPA_PLATFORM"] = "xcb"

# Disable GPIO warnings
GPIO.setwarnings(False)

# Define GPIO pins
LED_PIN = 23
BUZZER_PIN = 24  # GPIO pin for the buzzer
VIBRATION_PIN = 25  # GPIO pin for the vibration motor

# Setup GPIO
GPIO.setmode(GPIO.BCM)
GPIO.setup(LED_PIN, GPIO.OUT)
GPIO.setup(BUZZER_PIN, GPIO.OUT)
GPIO.setup(VIBRATION_PIN, GPIO.OUT)

# Initialize the camera and face detection modules
cap = cv2.VideoCapture(0)  # Open webcam
hog_face_detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("/home/pi/Downloads/drowsinessDetector-master/shape_predictor_68_face_landmarks.dat")

# MQTT Broker Details (Local Mosquitto for Node-RED)
MQTT_BROKER = "localhost"  # Local broker on the Raspberry Pi
MQTT_PORT = 1883  # Default MQTT port (no TLS)
MQTT_TOPIC = "status"  # MQTT topic for Node-RED to subscribe to

# Initialize MQTT Client
mqtt_client = mqtt.Client()

def connect_mqtt():
    """Connect to the local MQTT broker."""
    try:
        mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
        print("Connected to MQTT Broker!")
    except Exception as e:
        print(f"Failed to connect to MQTT Broker: {e}")

def publish_status(status, led_state, buzzer_state, vibration_state):
    """Publish driver status and device states to the MQTT topic."""
    payload = {
        "status": status,
        "led": led_state,
        "buzzer": buzzer_state,
        "vibration": vibration_state,
        "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    json_payload = json.dumps(payload)
    print(f"Publishing: {json_payload}")
    try:
        mqtt_client.publish(MQTT_TOPIC, json_payload)
        print(f"Published: {json_payload}")
    except Exception as e:
        print(f"Failed to publish status: {e}")

# Connect to MQTT Broker
connect_mqtt()

# State variables
sleep = 0
drowsy = 0
active = 0
status = ""
color = (0, 0, 0)

def compute(ptA, ptB):
    """Compute Euclidean distance between two points."""
    return np.linalg.norm(ptA - ptB)

def get_eye_aspect_ratio(eye_points):
    """Calculate the eye aspect ratio (EAR) for a set of eye landmarks."""
    # Eye landmarks: [0] and [3] are horizontal endpoints, [1][5] and [2][4] are vertical pairs
    horz_dist = compute(eye_points[0], eye_points[3])
    vert_dist1 = compute(eye_points[1], eye_points[5])
    vert_dist2 = compute(eye_points[2], eye_points[4])
    ear = (vert_dist1 + vert_dist2) / (2.0 * horz_dist)
    return ear

def blinked(left_eye, right_eye):
    """Determine blink state based on eye aspect ratios."""
    left_ear = get_eye_aspect_ratio(left_eye)
    right_ear = get_eye_aspect_ratio(right_eye)
    avg_ear = (left_ear + right_ear) / 2.0

    # Adjusted thresholds for robustness across angles
    if avg_ear > 0.25:
        return 2  # Eyes open
    elif 0.18 < avg_ear <= 0.25:  # Lowered drowsy threshold for non-frontal faces
        return 1  # Drowsy
    else:
        return 0  # Eyes closed

def led_on():
    """Turn the LED on."""
    GPIO.output(LED_PIN, GPIO.HIGH)
    return "ON"

def led_off():
    """Turn the LED off."""
    GPIO.output(LED_PIN, GPIO.LOW)
    return "OFF"

def buzzer_on():
    """Turn the buzzer on."""
    GPIO.output(BUZZER_PIN, GPIO.HIGH)
    return "ON"

def buzzer_off():
    """Turn the buzzer off."""
    GPIO.output(BUZZER_PIN, GPIO.LOW)
    return "OFF"

def vibration_on():
    """Turn the vibration motor on."""
    GPIO.output(VIBRATION_PIN, GPIO.HIGH)
    return "ON"

def vibration_off():
    """Turn the vibration motor off."""
    GPIO.output(VIBRATION_PIN, GPIO.LOW)
    return "OFF"

# Improve face detection robustness by tweaking HOG parameters
def detect_faces(gray_frame):
    """Detect faces with adjusted HOG parameters for better angle tolerance."""
    # Increase upsampling to detect smaller or rotated faces
    faces = hog_face_detector(gray_frame, 1)  # Upsample once
    if not faces:  # If no faces detected, try with more aggressive upsampling
        faces = hog_face_detector(gray_frame, 2)
    return faces

# Main loop with graceful exit
try:
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Failed to capture frame")
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detect_faces(gray)

        for face in faces:
            x, y, w, h = face.left(), face.top(), face.width(), face.height()
            cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

            landmarks = predictor(gray, face)
            landmarks = face_utils.shape_to_np(landmarks)

            # Extract eye landmarks (left: 36-41, right: 42-47)
            left_eye = landmarks[36:42]
            right_eye = landmarks[42:48]

            blink_state = blinked(left_eye, right_eye)

            if blink_state == 0:
                sleep += 1
                drowsy = 0
                active = 0
                if sleep > 6:
                    status = "SLEEPING !!!"
                    color = (0, 0, 255)
                    led_state = led_on()
                    buzzer_state = buzzer_on()
                    vibration_state = vibration_on()
                    publish_status(status, led_state, buzzer_state, vibration_state)

            elif blink_state == 1:
                sleep = 0
                active = 0
                drowsy += 1
                if drowsy > 6:
                    status = "DROWSY !"
                    color = (0, 0, 255)
                    led_state = led_on()
                    buzzer_state = buzzer_on()
                    vibration_state = vibration_on()
                    publish_status(status, led_state, buzzer_state, vibration_state)

            else:
                sleep = 0
                drowsy = 0
                active += 1
                if active > 6:
                    status = "ACTIVE :)"
                    color = (0, 255, 0)
                    led_state = led_off()
                    buzzer_state = buzzer_off()
                    vibration_state = vibration_off()
                    publish_status(status, led_state, buzzer_state, vibration_state)

            cv2.putText(frame, status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
            for n in range(0, 68):
                (x, y) = landmarks[n]
                cv2.circle(frame, (x, y), 1, (255, 255, 255), -1)

        cv2.imshow("Driver Drowsiness Detection", frame)

        # Check for exit key (ESC)
        if cv2.waitKey(1) == 27:  # ESC key
            break

except KeyboardInterrupt:
    print("Program interrupted. Exiting...")

finally:
    cap.release()
    cv2.destroyAllWindows()
    GPIO.cleanup()  # Cleanup GPIO pins
    mqtt_client.disconnect()  # Disconnect from MQTT broker